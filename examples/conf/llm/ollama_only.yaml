# 只使用 ollama 本地模型，不需要 API Key
name: ollama_llm

# 移除需要 API Key 的 providers，只保留本地配置
providers: {}

function_call:
  # 使用本地 ollama
  model_name: "ollama_chat/qwen3:4b-instruct-2507-q4_K_M"
  backend: litellm
  backend_params:
    base_url: "http://192.168.111.3:11434"
