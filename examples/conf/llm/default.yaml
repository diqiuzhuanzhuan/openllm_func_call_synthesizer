# structured config for LLM settings
# name is optional identifier
name: default_llm

providers:
  openai:
    backend: "openai"
    models:
      - "gpt-4o"
      - "gpt-4o-mini"
      - "gpt-3.5-turbo"
  
  anthropic:
    backend: "openai"
    models:
      - "claude-sonnet-4-20250514"
      - "claude-3-5-sonnet-20241022"

  google:
    backend: "openai"
    models:
      - "gemini-2.5-flash-lite"

function_call:
  # for ollama
  model_name: "ollama_chat/qwen3:4b-instruct-2507-q4_K_M"
  backend: litellm
  backend_params:
    base_url: "http://192.168.111.3:11434"
  # for openai
  #model_name: "gpt-4o"
  #backend: "openai"

