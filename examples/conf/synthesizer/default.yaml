# settings controlling the synthesizer behaviour
name: "default_synthesizer"

mcp_servers:
  "ugreen_mcp":
    transport: "http://192.168.111.9:12000/mcp"

choose_tools: ["search_photos", "create_album"]  #  false ["search_photos", "create_album", "get_album_list", "music_play_control", "music_search_control","music_settings_control", "video_search_control", "video_play_control", "get_system_info"]

query_generation:
  function_docs: examples/function_docs.json

  languages:
    - English
    - Chinese
    - Japanese
    - German
#    - French
#    - Spanish

  name: "function_query"
  output_dir: "data"
  output_format: "jsonl"   # or "json", "csv", "parquet"

  providers:
    openai:
      backend: "openai"
      models:
        - "gpt-4o"
        - "gpt-4o-mini"
        - "gpt-5-mini-2025-08-07"
        - "gpt-4.1"
      backend_params:
        max_concurrent_requests: 100
        require_all_responses: False

    anthropic:
      backend: "openai"
      models:
        - "claude-sonnet-4-20250514"
        - "claude-sonnet-4-5-20250929"
      backend_params:
        max_concurrent_requests: 100
        require_all_responses: False

    google:
      backend: "openai"
      models:
        #- "gemini/gemini-2.5-pro-nothinking"
        - "gemini-2.5-pro-nothinking"
      backend_params:
        max_concurrent_requests: 100
        require_all_responses: False

function_call_generation:
  function_dataset: "function_call"
  max_num: -1 # max number of function calls to generate, -1 means all
  output_dir: "data"
  output_format: "jsonl"   # or "json", "csv", "parquet"
  #name: "data/ollama_ugreen_function_call"
  name: "gpt_4o"
  provider:
    model_name: "gpt-4o"
    backend: "openai"
    backend_params:
      require_all_responses: False
      max_concurrent_requests: 100


critic:
  function_call_dataset: "/data0/work/SusieSu/project/openllm_datas/data_1117"  #"function_call/gpt_4o"
  output_dir: "/data0/work/SusieSu/project/openllm_datas"  #"data"
  # cirtic need 'query', 'label', 'task_prompt'
  query_field: "query"
  task_prompt_field: "prompt"
  label_field: "function_call"
  functions_field: "functions"
  response_field: "answer"
  output_format: "jsonl"   # or "json", "csv", xlsx, "parquet"
  name: "critic_gpt-5-mini-2025-08-07_1117"
  provider:
    model_name: "gpt-5-mini-2025-08-07"
    backend: "openai"
    backend_params:
      require_all_responses: False
      max_concurrent_requests: 100
